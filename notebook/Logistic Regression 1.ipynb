{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI-UA 0473 - Introduction to Machine Learning\n",
    "## Wednesday, February 1, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "\n",
    "### Key Points\n",
    "SETUP: We have a set of data points $\\{(x_{1}, y_{1}), (x_{2}, y_{2}), ... , (x_{n}, y_{n})\\}$, where $x_{i} \\in R^{d}$ are the feature vectors and $y_{i} \\in \\{0, 1\\}$ are the class labels.\n",
    "\n",
    "MODEL: $p_{+} = p(y = 1|x) = \\frac{1}{1 + e^{-w.x + b}}$, where $w, b \\in R^{d}$\n",
    "\n",
    "DISTANCE FUNCTION: -$(y * log(p_{+}) + (1 - y) * log(1 - p_{+}))$\n",
    "\n",
    "LEARNING RULE: $w \\leftarrow w - \\eta * (\\hat{y} - y) * x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample dataset preparation\n",
    "\n",
    "n_dim = 2\n",
    "x_train, y_train = make_blobs(n_samples=100, n_features=n_dim, centers=[[1,1],[-1,-1]], shuffle=True)\n",
    "x_test, y_test = make_blobs(n_samples=100, n_features=n_dim, centers=[[1,1],[-1,-1]], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sigmoid function.\n",
    "\n",
    "INPUT: A scalar/vector\n",
    "OUTPUT: A value between (0, 1) for each input component\n",
    "'''\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1. / (1. + numpy.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the logistic regression model.\n",
    "\n",
    "INPUT: Feature vector (x) and weight vector (w)\n",
    "OUTPUT: The probability of each data point belonging to the positive class.\n",
    "'''\n",
    "\n",
    "def logreg(x, w, pre=False):\n",
    "    x = x.reshape([1, -1]) if len(x.shape) < 2 else x\n",
    "    \n",
    "    y = numpy.sum(x * w[None,:-1], axis=1) + w[-1]\n",
    "    if pre:\n",
    "        return y    \n",
    "    return sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Distance function of the logistic regression model (popularly called likelihood). \n",
    "\n",
    "INPUT: True labels (y), feature vector (x) and weight vector (w)\n",
    "OUTPUT: Log of the likelihood for the given 'w'\n",
    "'''\n",
    "\n",
    "def logreg_dist(y, x, w, avg=False):\n",
    "    y_ = logreg(x, w)\n",
    "    \n",
    "    d = -(y * numpy.log(y_) + (1. - y) * numpy.log(1-y_))\n",
    "    \n",
    "    if not avg:\n",
    "        return d\n",
    "    return numpy.mean(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Learning rule for the logistic regression model.\n",
    "\n",
    "INPUT: True labels (y), feature vector (x) and weight vector (w)\n",
    "OUTPUT: The direction of update for the weight vector\n",
    "'''\n",
    "\n",
    "def logreg_rule(y, x, w):\n",
    "    y_ = logreg(x, w)\n",
    "    dw = numpy.zeros(w.shape)\n",
    "    dw[:-1] = numpy.mean((y_ - y)[:, None] * x, axis=0)\n",
    "    dw[-1] = numpy.mean(y_ - y)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing the weight vector randomly\n",
    "w0 = numpy.random.randn(n_dim+1); w0[-1] = 0.\n",
    "w = numpy.copy(w0)\n",
    "\n",
    "n_iter = 1000\n",
    "eta = .1   # Learning rate\n",
    "old_cost = numpy.Inf\n",
    "\n",
    "for ni in range(n_iter):\n",
    "    pred_y = logreg(x_train, w)\n",
    "    \n",
    "    w -= eta * logreg_rule(y_train, x_train, w)    # Updating the weight vector\n",
    "    \n",
    "    cost = logreg_dist(y_train, x_train, w, avg=True)\n",
    "    \n",
    "    if numpy.mod(ni, 50) == 0:\n",
    "        print('Logistic regression cost {} after iteration {}'.format(cost, ni))\n",
    "    if cost < 1e-16 or cost / old_cost >= 1.:\n",
    "        print('Converged')\n",
    "        break\n",
    "    old_cost = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Initial: {:.2} x_1 + {:.2} x_2 + {:.2} = 0'.format(*list(w0)))\n",
    "print('Final: {:.2} x_1 + {:.2} x_2 + {:.2} = 0'.format(*list(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize data \n",
    "def vis_data(x, y = None, c='r', open_figure=False):\n",
    "    if open_figure:\n",
    "        plot.figure()\n",
    "    if y is None: \n",
    "        y = [None] * len(x)\n",
    "    plot.hold('on')\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if y_ is None:\n",
    "            plot.plot(x_[0], x_[1], 'o', markerfacecolor='none', markeredgecolor=c)\n",
    "        else:\n",
    "            plot.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n",
    "    plot.hold('off')\n",
    "    plot.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_hyperplane(w, typ='k--'):\n",
    "    plot.hold('on')\n",
    "\n",
    "    lim0 = plot.gca().get_xlim()\n",
    "    lim1 = plot.gca().get_ylim()\n",
    "    m0, m1 = lim0[0], lim0[1]\n",
    "\n",
    "    intercept0 = -(w[0] * m0 + w[-1])/w[1]\n",
    "    intercept1 = -(w[0] * m1 + w[-1])/w[1]\n",
    "    \n",
    "    plt1, = plot.plot([m0, m1], [intercept0, intercept1], typ)\n",
    "\n",
    "    plot.gca().set_xlim(lim0)\n",
    "    plot.gca().set_ylim(lim1)\n",
    "    \n",
    "    plot.hold('off')\n",
    "    \n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_decision_boundary_contour(w, typ='k--'):\n",
    "    plot.hold('on')\n",
    "    \n",
    "    lim0 = plot.gca().get_xlim()\n",
    "    lim1 = plot.gca().get_ylim()\n",
    "    \n",
    "    x_ = numpy.linspace(lim0[0], lim0[1], 100)\n",
    "    y_ = numpy.linspace(lim1[0], lim1[1], 100)\n",
    "    xx, yy = numpy.meshgrid(x_, y_)\n",
    "    \n",
    "    x_tra_ = numpy.concatenate([xx.ravel()[:,None], yy.ravel()[:,None]], axis=1)\n",
    "    \n",
    "    pred = logreg(x_tra_, w)\n",
    "    plt1 = plot.contourf(xx, yy, pred.reshape(xx.shape), cmap=plot.cm.coolwarm, alpha=0.4)\n",
    "    \n",
    "    plot.colorbar(plt1)\n",
    "    \n",
    "    plot.gca().set_xlim(lim0)\n",
    "    plot.gca().set_ylim(lim1)\n",
    "    \n",
    "    plot.hold('off')\n",
    "    \n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot.figure()\n",
    "\n",
    "vis_data(x_train, y_train, c='r')\n",
    "\n",
    "plt0 = vis_hyperplane(w0, 'k-.')\n",
    "plt1 = vis_hyperplane(w, 'k--')\n",
    "plot.legend([plt0, plt1], [\n",
    "        'Initial: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w0)),\n",
    "        'Final: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w))],\n",
    "           loc='best')\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis_data(x_train, y_train, c= 'r', open_figure=True)\n",
    "vis_decision_boundary_contour(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision boundary on test data\n",
    "\n",
    "plot.figure()\n",
    "\n",
    "vis_data(x_test, y_test, 'b')\n",
    "\n",
    "plt1 = vis_hyperplane(w, 'k--')\n",
    "\n",
    "plot.legend([plt0, plt1], [\n",
    "        'Initial: {:.2} x_1 + {:.2} x_2 + {:.2} = 0'.format(*list(w0)),\n",
    "        'Final: {:.2} x_1 + {:.2} x_2 + {:.2} = 0'.format(*list(w))],\n",
    "           loc='upper right')\n",
    "\n",
    "plot.legend(fontsize = 20, loc = 'best')\n",
    "plot.title('Decision boundary on test data')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_error = numpy.sum(numpy.abs(numpy.round(logreg(x_train, w)) - y_train)) / numpy.float(len(y_train))\n",
    "test_error = numpy.sum(numpy.abs(numpy.round(logreg(x_test, w)) - y_test)) / numpy.float(len(y_test))\n",
    "\n",
    "print('Training error rate {}, Test error rate {}'.format(train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. HOMEWORK - Use scikit-learn to replicate the above operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this cell to import required packages of sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 1: Create a Logistic Regression class instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 2: Fit the logistic regression model to the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Obtain the coefficients of the learned model (read the documentation to find out how)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Compare the feature coefficients obtained by sklearn and the custom module we have\n",
    "\n",
    "# Note: Print the equations of the model learned by both implementations and comment about what you observe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 5: Predict the class of test data points. Print the TRAINING and TEST accuracy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
